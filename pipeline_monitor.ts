/**
 * Waterfall Pipeline Test Runner
 * 
 * Tests the new 3-stage decoupled architecture:
 * 1. Scraper ‚Üí DISCOVERED/AWAITING_ENRICHMENT
 * 2. Enrichment Worker ‚Üí READY_TO_INDEX
 * 3. Indexing Worker ‚Üí PROCESSED (events table)
 */

import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const envText = await Deno.readTextFile(".env");
const env: Record<string, string> = {};
envText.split("\n").forEach((line) => {
  const [key, ...val] = line.split("=");
  if (key && val.length > 0) {
    env[key.trim()] = val.join("=").trim().replace(/^["']|["']$/g, "");
  }
});

const supabase = createClient(env.SUPABASE_URL, env.SUPABASE_SERVICE_ROLE_KEY);

console.log("‚ïê".repeat(60));
console.log("  WATERFALL PIPELINE STATUS MONITOR");
console.log("‚ïê".repeat(60));
console.log();

// Get pipeline status summary
const { data: stagingData } = await supabase
  .from("raw_event_staging")
  .select("pipeline_status, status");

// Count by pipeline_status (new column)
const pipelineCounts: Record<string, number> = {};
const legacyCounts: Record<string, number> = {};

stagingData?.forEach((row: any) => {
  if (row.pipeline_status) {
    pipelineCounts[row.pipeline_status] = (pipelineCounts[row.pipeline_status] || 0) + 1;
  }
  if (row.status) {
    legacyCounts[String(row.status)] = (legacyCounts[String(row.status)] || 0) + 1;
  }
});

console.log("üìä PIPELINE STATUS (New Waterfall)");
console.log("‚îÄ".repeat(40));
const pipelineStages = [
  "discovered",
  "awaiting_enrichment", 
  "enriching",
  "enriched",
  "ready_to_index",
  "indexing",
  "processed",
  "failed"
];

pipelineStages.forEach(status => {
  const count = pipelineCounts[status] || 0;
  const bar = "‚ñà".repeat(Math.min(count, 30));
  const emoji = status === "processed" ? "‚úÖ" : 
                status === "failed" ? "‚ùå" : 
                status.includes("ing") ? "‚è≥" : "üìã";
  console.log(`${emoji} ${status.padEnd(20)} ${String(count).padStart(4)} ${bar}`);
});

console.log();
console.log("üìä LEGACY STATUS (Old Column)");
console.log("‚îÄ".repeat(40));
Object.entries(legacyCounts).forEach(([status, count]) => {
  console.log(`   ${status.padEnd(20)} ${String(count).padStart(4)}`);
});

// Get events count
const { count: eventsCount } = await supabase
  .from("events")
  .select("*", { count: "exact", head: true });

const { count: queueCount } = await supabase
  .from("ai_job_queue")
  .select("*", { count: "exact", head: true });

console.log();
console.log("üìä OUTPUT TABLES");
console.log("‚îÄ".repeat(40));
console.log(`üìÖ events table:     ${eventsCount || 0} published events`);
console.log(`ü§ñ ai_job_queue:     ${queueCount || 0} embedding jobs`);

console.log();
console.log("‚ïê".repeat(60));
console.log("  ARCHITECTURE OVERVIEW");
console.log("‚ïê".repeat(60));
console.log(`
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SCRAPER       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ENRICHMENT      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ INDEXING        ‚îÇ
‚îÇ   (Harvester)   ‚îÇ     ‚îÇ (Deep Dive)     ‚îÇ     ‚îÇ (Finalize)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº                       ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ DISCOVERED‚îÇ           ‚îÇREADY_TO_  ‚îÇ           ‚îÇ PROCESSED ‚îÇ
  ‚îÇ    or     ‚îÇ    ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ  INDEX    ‚îÇ    ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ  (events) ‚îÇ
  ‚îÇ AWAITING  ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
`);

console.log("üìù NEXT STEPS:");
console.log("‚îÄ".repeat(40));
if ((pipelineCounts["awaiting_enrichment"] || 0) > 0 || (pipelineCounts["discovered"] || 0) > 0) {
  console.log("1. Apply migration: supabase/migrations/20260128001000_waterfall_pipeline_architecture.sql");
  console.log("2. Run enrichment: deno run --allow-all test_enrichment_worker.ts");
  console.log("3. Run indexing:   deno run --allow-all test_indexing_worker.ts");
} else if ((pipelineCounts["ready_to_index"] || 0) > 0) {
  console.log("Events ready! Run indexing worker to move them to events table.");
} else if ((eventsCount || 0) > 0) {
  console.log("‚úÖ Pipeline complete! Events are published.");
} else {
  console.log("Run the scraper first: deno run --allow-all run_pipeline.ts");
}
