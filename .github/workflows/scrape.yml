name: scheduled-scrape
on:
  schedule:
    - cron: '0 3 * * *' # daily at 03:00 UTC (configurable)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Invoke Supabase Edge Function - run-scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "üöÄ Triggering scraper at $(date -u)"
          
          # Invoke the run-scraper edge function
          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
            "${SUPABASE_URL}/functions/v1/run-scraper" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${SUPABASE_SERVICE_ROLE_KEY}" \
            -d '{"enableDeepScraping": true}')
          
          # Extract HTTP status code (last line)
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          # Extract response body (all but last line)
          BODY=$(echo "$RESPONSE" | sed '$d')
          
          echo "üìã Response (HTTP $HTTP_CODE):"
          
          # Validate JSON and pretty-print, or show raw body if invalid
          if echo "$BODY" | jq . > /tmp/parsed.json 2>/dev/null; then
            cat /tmp/parsed.json
          else
            echo "‚ö†Ô∏è Response is not valid JSON:"
            echo "$BODY"
          fi
          
          # Check if request was successful
          if [[ "$HTTP_CODE" -ge 200 && "$HTTP_CODE" -lt 300 ]]; then
            echo "‚úÖ Scraper invoked successfully"
            
            # Extract stats from response (with JSON validation)
            if echo "$BODY" | jq empty 2>/dev/null; then
              SUCCESS=$(echo "$BODY" | jq -r '.success // false')
              TOTAL_SOURCES=$(echo "$BODY" | jq -r '.stats.totalSources // 0')
              INSERTED=$(echo "$BODY" | jq -r '.stats.totalEventsInserted // 0')
              FAILED=$(echo "$BODY" | jq -r '.stats.totalEventsFailed // 0')
              
              echo ""
              echo "üìä Summary:"
              echo "   Success: $SUCCESS"
              echo "   Total Sources: $TOTAL_SOURCES"
              echo "   Events Inserted: $INSERTED"
              echo "   Events Failed: $FAILED"
              
              if [[ "$SUCCESS" != "true" ]]; then
                echo "‚ö†Ô∏è Scraper returned success=false"
                exit 1
              fi
            else
              echo "‚ö†Ô∏è Unable to parse response as JSON, treating as error"
              exit 1
            fi
          else
            echo "‚ùå Error: Scraper invocation failed with HTTP $HTTP_CODE"
            exit 1
          fi
